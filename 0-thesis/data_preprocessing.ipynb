{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c5e34",
   "metadata": {},
   "source": [
    "### Bond Issues\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72644763",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "base_dir = 'data/source/bond_issues/'\n",
    "\n",
    "for file in os.listdir(base_dir):\n",
    "    \n",
    "    # bond issues\n",
    "    curr_bond_issues = pd.read_csv(base_dir + file, delimiter=';')\n",
    "    \n",
    "    # uniform column names\n",
    "    curr_bond_issues.columns = [\n",
    "        x.lower().replace('_', ' ').title().replace(' ', '') for x in curr_bond_issues.columns\n",
    "    ]\n",
    "    \n",
    "    # local save\n",
    "    acc.append(curr_bond_issues)\n",
    "    \n",
    "# combine dfs\n",
    "bond_issues = pd.concat([acc[i] for i in range(len(acc))], axis=0)\n",
    "\n",
    "# drop empty columns\n",
    "bond_issues = bond_issues.dropna(how='all', axis=1)\n",
    "\n",
    "# drop duplicates along the whole dataset\n",
    "bond_issues = bond_issues.drop_duplicates()\n",
    "\n",
    "# save\n",
    "bond_issues.to_csv('data/processed/bond_issues.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01f901f",
   "metadata": {},
   "source": [
    "### Bond Issuers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3fce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bond issuers\n",
    "bond_issuers = pd.read_csv('data/source/bond_issuers.csv', delimiter=',', low_memory=False)\n",
    "\n",
    "# uniform column names\n",
    "bond_issuers.columns = [\n",
    "    x.lower().replace('_', ' ').title().replace(' ', '') for x in bond_issuers.columns\n",
    "]\n",
    "\n",
    "# drop duplicates along the whole dataset\n",
    "bond_issuers = bond_issuers.drop_duplicates()\n",
    "\n",
    "# drop empty columns\n",
    "bond_issuers = bond_issuers.dropna(how='all', axis=1)\n",
    "\n",
    "# remove commas from string values\n",
    "cols = ['CusipName', 'LegalName', 'Addr1', 'Addr2', 'City', 'Zipcode', 'Province', 'MainPhone', 'MainFax', 'Note']\n",
    "for col in cols:\n",
    "    bond_issuers[col] = bond_issuers[col].str.replace(',', '')\n",
    "\n",
    "# cast float(NaNs) to int \n",
    "bond_issuers['SicCode'] = bond_issuers['SicCode'].astype('Int64')\n",
    "bond_issuers['ParentId'] = bond_issuers['ParentId'].astype('Int64')\n",
    "bond_issuers['NaicsCode'] = bond_issuers['NaicsCode'].astype('Int64')\n",
    "bond_issuers['IndustryGroup'] = bond_issuers['IndustryGroup'].astype('Int64')\n",
    "\n",
    "# save\n",
    "bond_issuers.to_csv('data/processed/bond_issuers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e74063",
   "metadata": {},
   "source": [
    "### Bond Ratings\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2416908",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "base_dir = 'data/source/bond_ratings/'\n",
    "\n",
    "for file in os.listdir(base_dir):\n",
    "    \n",
    "    # bond ratings\n",
    "    curr_bond_ratings = pd.read_csv(base_dir + file, delimiter=';', low_memory=False)\n",
    "\n",
    "    # uniform column names\n",
    "    curr_bond_ratings.columns = [\n",
    "        x.lower().replace('_', ' ').title().replace(' ', '') for x in curr_bond_ratings.columns\n",
    "    ]\n",
    "\n",
    "    # drop duplicates\n",
    "    curr_bond_ratings = curr_bond_ratings.sort_values(by=['InvestmentGrade'])\n",
    "    curr_bond_ratings = curr_bond_ratings.drop_duplicates(\n",
    "        subset=['CompleteCusip', 'RatingDate', 'RatingType'], keep='first'\n",
    "    )\n",
    "\n",
    "    # rating mapping\n",
    "    with open('rating_eq.pickle', 'rb') as handle:\n",
    "        rating_eq = pickle.load(handle)\n",
    "    curr_bond_ratings['RatingCategory'] = curr_bond_ratings['Rating'].map(rating_eq).astype('Int64')\n",
    "    \n",
    "    # local save\n",
    "    acc.append(curr_bond_ratings)\n",
    "\n",
    "# combine dfs\n",
    "bond_ratings = pd.concat([acc[i] for i in range(len(acc))], axis=0)\n",
    "\n",
    "# drop duplicates along the whole dataset\n",
    "bond_ratings = bond_ratings.drop_duplicates()\n",
    "\n",
    "# save\n",
    "bond_ratings.to_csv('data/processed/bond_ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e1624",
   "metadata": {},
   "source": [
    "### Trace\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3c42c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir = 'data/source/trace/'\n",
    "\n",
    "for file in tqdm(os.listdir(base_dir), desc=\"Processing records\"):\n",
    "    \n",
    "    # trace\n",
    "    curr_trace = pd.read_csv(base_dir + file, delimiter=';', low_memory=False)\n",
    "    \n",
    "    # drop blank columns\n",
    "    curr_trace = curr_trace.drop(['asof_cd', 'spcl_trd_fl'], axis=1)\n",
    "    \n",
    "    # remove commas from columns\n",
    "    curr_trace['bond_sym_id'] = curr_trace['bond_sym_id'].str.replace(',', '.')\n",
    "\n",
    "    # uniform column names\n",
    "    curr_trace.columns = [x.lower().replace('_', ' ').title().replace(' ', '') for x in curr_trace.columns]\n",
    "    \n",
    "    # save\n",
    "    curr_trace.to_csv('data/processed/trace/{}'.format(file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1cdf1",
   "metadata": {},
   "source": [
    "### CRSPC Factors\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13565937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crspc factors\n",
    "crspc_factors = pd.read_csv('data/source/crspc/factors.csv', delimiter=',', low_memory=False)\n",
    "\n",
    "# transform date column\n",
    "crspc_factors['Date'] = pd.to_datetime(crspc_factors['Date'], format='%Y%m%d')\n",
    "\n",
    "# rename columns\n",
    "crspc_factors.columns = ['Date', 'MktRf', 'Smb', 'Hml', 'Rmw', 'Cma', 'Rf', 'Rm']\n",
    "\n",
    "# save\n",
    "crspc_factors.to_csv('data/processed/crspc/factors.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad5036",
   "metadata": {},
   "source": [
    "### CRPSC Daily Securities\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c86bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# column selection and renaming\n",
    "col = [\n",
    "    'LPERMNO', 'LPERMCO', 'datadate', 'tic', 'cusip', 'conm', 'div', 'curcdd', 'cshoc', 'cshtrd', 'eps', 'epsmo',\n",
    "    'prccd','prchd', 'prcld', 'prcod', 'prcstd', 'trfd', 'exchg', 'secstat', 'loc', 'naics', 'sic', 'ipodate'\n",
    "] # shrcd = 10, 11\n",
    "rcol = [\n",
    "    'LPermNo', 'LPermCo', 'DataDate', 'Tic', 'Cusip', 'CoNm', 'Div', 'CurCdd', 'Cshoc', 'CshTrd', 'Eps', 'EpsMo',\n",
    "    'PrcCd', 'PrcHd', 'PrcLd', 'PrcOd', 'PrcStd', 'TrFd', 'Exchg', 'SecStat', 'Loc', 'Naics', 'Sic', 'IpoDate'\n",
    "]\n",
    "\n",
    "# crspc daily first file\n",
    "crspc_daily = pd.read_csv('data/source/crspc/CRSPC_12-2002.csv', chunksize=500000, delimiter=',', low_memory=False)\n",
    "\n",
    "for i, chunk in enumerate(crspc_daily):\n",
    "    \n",
    "    chunk = chunk[col]\n",
    "    chunk.columns = rcol\n",
    "    \n",
    "    # transform date column\n",
    "    chunk['IpoDate'] =  pd.to_datetime(chunk['IpoDate'], format='%Y%m%d')\n",
    "    \n",
    "    # save\n",
    "    chunk.to_csv('data/processed/crspc/securities_daily/securities{}.csv'.format(i), index=False)\n",
    "\n",
    "cnt = i + 1 # file counter\n",
    "    \n",
    "# crspc daily second file\n",
    "crspc_daily = pd.read_csv('data/source/crspc/CRSPC_06-2022.csv', chunksize=500000, delimiter=',', low_memory=False)\n",
    "\n",
    "for i, chunk in enumerate(crspc_daily):\n",
    "    \n",
    "    chunk = chunk[col]\n",
    "    chunk.columns = rcol\n",
    "    \n",
    "    # transform date column\n",
    "    chunk['IpoDate'] =  pd.to_datetime(chunk['IpoDate'], format='%Y%m%d')\n",
    "    \n",
    "    # save\n",
    "    chunk.to_csv('data/processed/crspc/securities_daily/securities{}.csv'.format(i+cnt), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
