{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01f901f",
   "metadata": {},
   "source": [
    "### Bond Issuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3fce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bond issuers\n",
    "bond_issuers = pd.read_csv(\n",
    "    'data/source/bond_issuers.csv', delimiter=',', low_memory=False, encoding='utf-8'\n",
    ")\n",
    "\n",
    "# uniform column names\n",
    "bond_issuers.columns = [\n",
    "    x.lower().replace('_', ' ').title().replace(' ', '') for x in bond_issuers.columns\n",
    "]\n",
    "\n",
    "# drop duplicates along the whole dataset\n",
    "bond_issuers = bond_issuers.drop_duplicates()\n",
    "\n",
    "# drop empty columns\n",
    "bond_issuers = bond_issuers.dropna(how='all', axis=1)\n",
    "\n",
    "# remove commas from string values\n",
    "cols = [\n",
    "    'CusipName', 'LegalName', 'Addr1', 'Addr2', 'City', \n",
    "    'Zipcode', 'Province', 'MainPhone', 'MainFax', 'Note'\n",
    "]\n",
    "for col in cols:\n",
    "    bond_issuers[col] = bond_issuers[col].str.replace(',', '')\n",
    "\n",
    "# cast float(NaNs) to int \n",
    "bond_issuers = bond_issuers.assign(\n",
    "    SicCode = bond_issuers['SicCode'].astype('Int64'),\n",
    "    ParentId = bond_issuers['ParentId'].astype('Int64'),\n",
    "    NaicsCode = bond_issuers['NaicsCode'].astype('Int64'),\n",
    "    IndustryGroup = bond_issuers['IndustryGroup'].astype('Int64')\n",
    ")\n",
    "\n",
    "# save\n",
    "bond_issuers.to_csv('data/processed/bond_issuers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c5e34",
   "metadata": {},
   "source": [
    "### Bond Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72644763",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "base_dir = 'data/source/bond_issues/'\n",
    "\n",
    "for file in os.listdir(base_dir):\n",
    "    \n",
    "    # bond issues\n",
    "    curr_bond_issues = pd.read_csv(\n",
    "        base_dir + file, delimiter=';', encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    # uniform column names\n",
    "    curr_bond_issues.columns = [\n",
    "        x.lower().replace('_', ' ').title().replace(' ', '') for x in curr_bond_issues.columns\n",
    "    ]\n",
    "    \n",
    "    # transform dates\n",
    "    curr_bond_issues = curr_bond_issues.assign(\n",
    "        DatedDate = pd.to_datetime(\n",
    "            curr_bond_issues['DatedDate'], format='%Y%m%d', errors='coerce'\n",
    "        ),\n",
    "        FirstInterestDate = pd.to_datetime(\n",
    "            curr_bond_issues['FirstInterestDate'], format='%Y%m%d', errors='coerce'\n",
    "        ),\n",
    "        LastInterestDate = pd.to_datetime(\n",
    "            curr_bond_issues['LastInterestDate'], format='%Y%m%d', errors='coerce'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # local save\n",
    "    acc.append(curr_bond_issues)\n",
    "    \n",
    "# combine dfs\n",
    "bond_issues = pd.concat([acc[i] for i in range(len(acc))], axis=0)\n",
    "\n",
    "# drop empty columns\n",
    "bond_issues = bond_issues.dropna(how='all', axis=1)\n",
    "\n",
    "# drop duplicate Cusips\n",
    "bond_issues = bond_issues.sort_values(by=['FirstInterestDate'])\n",
    "bond_issues = bond_issues.drop_duplicates(\n",
    "        subset=['CompleteCusip'], keep='first'\n",
    "    )\n",
    "\n",
    "# save\n",
    "bond_issues.to_csv('data/processed/bond_issues.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e74063",
   "metadata": {},
   "source": [
    "### Bond Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2416908",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "base_dir = 'data/source/bond_ratings/'\n",
    "\n",
    "with open('pickle/rating_eq.pickle', 'rb') as handle:\n",
    "    rating_eq = pickle.load(handle)\n",
    "\n",
    "for file in tqdm(os.listdir(base_dir), desc='Processing records'):\n",
    "    \n",
    "    # bond ratings\n",
    "    curr_bond_ratings = pd.read_csv(\n",
    "        base_dir + file, delimiter=';', low_memory=False, encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    # uniform column names\n",
    "    curr_bond_ratings.columns = [\n",
    "        x.lower().replace('_', ' ').title().replace(' ', '') for x in curr_bond_ratings.columns\n",
    "    ]\n",
    "\n",
    "    # drop duplicates\n",
    "    curr_bond_ratings = curr_bond_ratings.sort_values(by=['InvestmentGrade'])\n",
    "    curr_bond_ratings = curr_bond_ratings.drop_duplicates(\n",
    "        subset=['CompleteCusip', 'RatingDate', 'RatingType'], keep='first'\n",
    "    )\n",
    "\n",
    "    # rating mapping\n",
    "    curr_bond_ratings['RatingCategory'] = curr_bond_ratings['Rating'].map(rating_eq).astype('Int64')\n",
    "    curr_bond_ratings['RatingCategory'] = curr_bond_ratings['RatingCategory'].fillna(0)\n",
    "    \n",
    "    # local save\n",
    "    acc.append(curr_bond_ratings)\n",
    "\n",
    "# combine dfs\n",
    "bond_ratings = pd.concat([acc[i] for i in range(len(acc))], axis=0)\n",
    "\n",
    "# drop duplicates along the whole dataset\n",
    "bond_ratings = bond_ratings.drop_duplicates()\n",
    "\n",
    "# save\n",
    "bond_ratings.to_csv('data/processed/bond_ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650adfd6",
   "metadata": {},
   "source": [
    "### Bond Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5c678",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "base_dir = 'data/source/bond_returns/'\n",
    "\n",
    "for file in tqdm(os.listdir(base_dir), desc='Processing records'):\n",
    "    \n",
    "    # bond retruns\n",
    "    curr_bond_ret = pd.read_csv(\n",
    "        base_dir + file, delimiter=',', low_memory=False, encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    # uniform columns names\n",
    "    columns = [\n",
    "        ''.join(x.lower().capitalize() for x in col.split('_')) for col in curr_bond_ret.columns\n",
    "    ]\n",
    "    curr_bond_ret.columns = columns\n",
    "    curr_bond_ret = curr_bond_ret.rename(\n",
    "        columns = {\n",
    "            'Coupamt': 'CoupAmt',\n",
    "            'Coupacc': 'CoupAcc',\n",
    "            'Nextcoup': 'NextCoup',\n",
    "            'Remcoups': 'RemCoups',\n",
    "            'Coupmonth': 'CoupMonth', \n",
    "            'Multicoups': 'MultiCoups'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # remove punctuation from columns\n",
    "    curr_bond_ret = curr_bond_ret.assign(\n",
    "        BondSymId = curr_bond_ret['BondSymId'].str.replace(',', '.'),\n",
    "        Yield = curr_bond_ret['Yield'].str.replace(',', '').str.replace('%', '').astype(float),\n",
    "        RetEom = curr_bond_ret['RetEom'].str.replace(',', '').str.replace('%', '').astype(float),\n",
    "        RetLdm = curr_bond_ret['RetLdm'].str.replace(',', '').str.replace('%', '').astype(float),\n",
    "        RetL5m = curr_bond_ret['RetL5m'].str.replace(',', '').str.replace('%', '').astype(float),\n",
    "        TSpread = curr_bond_ret['TSpread'].str.replace(',', '').str.replace('%', '').astype(float),\n",
    "        TVolume = curr_bond_ret['TVolume'].str.replace(',', '').str.replace('$', '', regex=True).astype('Int64'),\n",
    "        TDvolume = curr_bond_ret['TDvolume'].str.replace(',', '').str.replace('$', '', regex=True).astype('Int64')\n",
    "    )\n",
    "    \n",
    "    # drop duplicates along the whole dataset\n",
    "    curr_bond_ret = curr_bond_ret.drop_duplicates()\n",
    "\n",
    "    # local save\n",
    "    acc.append(curr_bond_ret)\n",
    "    \n",
    "# combine dfs\n",
    "bond_ret = pd.concat([acc[i] for i in range(len(acc))], axis=0)\n",
    "\n",
    "# drop duplicates along the whole dataset\n",
    "bond_ret = bond_ret.drop_duplicates()\n",
    "\n",
    "# save\n",
    "bond_ret.to_csv('data/processed/bond_returns.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1cdf1",
   "metadata": {},
   "source": [
    "### CRSPC Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13565937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crspc factors\n",
    "crspc_factors = pd.read_csv(\n",
    "    'data/source/crspc/factors.csv', delimiter=',', low_memory=False, encoding='utf-8'\n",
    ")\n",
    "\n",
    "# transform date column\n",
    "crspc_factors['Date'] = pd.to_datetime(crspc_factors['Date'], format='%Y%m%d')\n",
    "\n",
    "# rename columns\n",
    "crspc_factors.columns = ['Date', 'MktRf', 'Smb', 'Hml', 'Rmw', 'Cma', 'Rf', 'Rm']\n",
    "\n",
    "# save\n",
    "crspc_factors.to_csv('data/processed/crspc/factors.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad5036",
   "metadata": {},
   "source": [
    "### CRPSC Daily Securities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c86bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir = 'data/source/crspc/securities_daily/'\n",
    "\n",
    "for file in tqdm(os.listdir(base_dir), desc='Processing records'):\n",
    "\n",
    "    # securities daily\n",
    "    crspc_daily = pd.read_csv(\n",
    "        base_dir + file, delimiter=';', low_memory=False, encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    # uniform column names\n",
    "    crspc_daily.columns = [\n",
    "        'GvKey', 'IId', 'DataDate', 'Tic', 'Cusip', 'CoNml', 'PrcCd', 'PrcHd', 'PrcLd', \n",
    "        'PrcOd', 'PrcStd', 'Exchg', 'Exchange', 'Sic', 'Industry', 'Naics', 'Eps', 'EpsMo',\n",
    "        'TrFd', 'Loc', 'Div', 'Divd', 'DivdPayDateInd','Divsp', 'DivspPayDate', 'AnncDate', 'IpoDate'\n",
    "    ]\n",
    "    \n",
    "    # drop duplicates\n",
    "    crspc_daily = crspc_daily.drop_duplicates()\n",
    "    \n",
    "    # remove punctuation\n",
    "    crspc_daily['CoNml'] = crspc_daily['CoNml'].str.replace(',', '.')\n",
    "    \n",
    "    # save\n",
    "    crspc_daily.to_csv('data/processed/crspc/securities_daily/{}'.format(file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd89d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/source/crspc/'\n",
    "\n",
    "columns = [\n",
    "    'GVKEY', 'LPERMNO', 'iid', 'datadate', 'tic', 'cusip', 'conm', 'prccd', 'prchd', 'prcld', \n",
    "    'prcod', 'prcstd', 'exchg', 'exchange', 'sic', 'industry', 'naics', 'eps', 'epsmo',\n",
    "    'trfd', 'loc', 'div', 'divd', 'divdpaydateind','divsp', 'divsppaydate', 'anncdate', 'ipodate'\n",
    "]\n",
    "\n",
    "for file in ['CRSPC_12-2002.csv', 'CRSPC_06-2022.csv']:\n",
    "\n",
    "    # securities daily\n",
    "    crspc_daily = pd.read_csv(\n",
    "        base_dir + file, delimiter=';', low_memory=False, encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    # select columns\n",
    "    crspc_daily = crspc_daily[columns]\n",
    "    \n",
    "    # uniform column names\n",
    "    crspc_daily.columns = [\n",
    "        'GvKey', 'LPermNo', 'IId', 'DataDate', 'Tic', 'Cusip', 'CoNml', 'PrcCd', 'PrcHd', 'PrcLd', \n",
    "        'PrcOd', 'PrcStd', 'Exchg', 'Exchange', 'Sic', 'Industry', 'Naics', 'Eps', 'EpsMo',\n",
    "        'TrFd', 'Loc', 'Div', 'Divd', 'DivdPayDateInd','Divsp', 'DivspPayDate', 'AnncDate', 'IpoDate'\n",
    "    ]\n",
    "    \n",
    "    # drop duplicates\n",
    "    crspc_daily = crspc_daily.drop_duplicates()\n",
    "    \n",
    "    # transform date column\n",
    "    crspc_daily['IpoDate'] = pd.to_datetime(crspc_daily['IpoDate'], format='%Y%m%d')\n",
    "    \n",
    "    # remove punctuation\n",
    "    crspc_daily['CoNml'] = crspc_daily['CoNml'].str.replace(',', '.')\n",
    "    \n",
    "    # save\n",
    "    crspc_daily.to_csv('data/processed/crspc/{}'.format(file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e1624",
   "metadata": {},
   "source": [
    "### Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3c42c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir = 'data/source/trace/'\n",
    "\n",
    "for file in tqdm(os.listdir(base_dir), desc='Processing records'):\n",
    "    \n",
    "    # trace\n",
    "    curr_trace = pd.read_csv(\n",
    "        base_dir + file, delimiter=';', low_memory=False, encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    # drop blank columns\n",
    "    curr_trace = curr_trace.drop(['asof_cd', 'spcl_trd_fl'], axis=1)\n",
    "    \n",
    "    # remove commas from columns\n",
    "    curr_trace['bond_sym_id'] = curr_trace['bond_sym_id'].str.replace(',', '.')\n",
    "\n",
    "    # uniform column names\n",
    "    curr_trace.columns = [\n",
    "        x.lower().replace('_', ' ').title().replace(' ', '') for x in curr_trace.columns\n",
    "    ]\n",
    "    \n",
    "    # save\n",
    "    curr_trace.to_csv('data/processed/trace/{}'.format(file), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
